{"cells":[{"cell_type":"code","execution_count":null,"id":"a81242e5","metadata":{"id":"a81242e5"},"outputs":[],"source":["# MAIN PACKAGES\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","from tqdm import tqdm\n","\n","# MODEL VALIDATION\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","#MPNR SPECIFIC\n","from sklearn.neural_network import MLPRegressor\n","from sklearn import preprocessing\n","from sklearn.feature_selection import mutual_info_regression, SelectKBest\n","from sklearn.preprocessing import RobustScaler\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFlXeD5Fp1OH","executionInfo":{"status":"ok","timestamp":1690068158992,"user_tz":420,"elapsed":13898,"user":{"displayName":"Sarah Wait","userId":"14055064724979742320"}},"outputId":"4b7fc05e-1273-4543-ff5b-7af23446bb41"},"id":"yFlXeD5Fp1OH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["This notebook reads the top encoding datasets and uses them to form predictions on the Novel mutant library and saves predictions of the test set for cross validation.\n","\n","\n","Inputs:\n","1.   Combined Dataset Path (String)\n","2.   Desired Name of Dependent Variable (String)\n","3.   len(Sequence of Base Variant) (int)\n","4.   Property Matrix Path (String)\n","5.   path to parent folder\n","5.   path to MPNR/MPNR_Encoding_Datasets.csv\n","6.   path to Novel mutant library\n","\n","Outputs:\n","5 novel prediction notebooks\n","*   once per top five encoding datasets, the final predictions of the novel library are saved.\n","*   Saved as dataset_name_novel_library_predictions.csv in the MPNR/ Sub Folder\n","\n","5 test set prediction notebooks\n","*   once per top five encoding datasets, the final predictions of test set are saved.\n","*   Saved as dataset_name_test_set_predictions.csv in the MPNR/ Sub Folder\n","\n","\n"],"metadata":{"id":"8FZ1qUIQoGRt"},"id":"8FZ1qUIQoGRt"},{"cell_type":"code","execution_count":null,"id":"e122f17a","metadata":{"id":"e122f17a"},"outputs":[],"source":["mutation_datset_path = '/content/drive/MyDrive/ml_paper_ipnys/backend_data/combined_dataset.csv'\n","dependent_variable = 'Fluor Decay' # Desired Name of Dependent Variable\n","len_sequence_of_base_variant = 451 # len(Sequence of Base Variant)\n","encoding_dataset_path = '/content/drive/MyDrive/ml_paper_ipnys/backend_data/full_property_matrix.csv'\n","parent_folder_path = '2023-07-22-ensemble-run/' #should be created in wrapper\n","\n","# specific for this notebook\n","novel_library_path = '/content/drive/MyDrive/ml_paper_ipnys/backend_data/novel_mutant_library.csv'\n","top_encoding_dataset_path = '/content/drive/MyDrive/ml_paper_ipnys/KNR_Encoding_Datasets.csv'"]},{"cell_type":"code","source":["data = pd.read_csv(mutation_datset_path)\n","position_cols = np.arange(0,len_sequence_of_base_variant)\n","position_cols = [str(i) for i in position_cols]\n","encoded_df = data[position_cols]\n","\n","x_train, x_test, y_train, y_test = train_test_split(encoded_df,\n","                                                    data[dependent_variable],\n","                                                    test_size=0.20,\n","                                                    random_state=42)"],"metadata":{"id":"xPI4iKhpoULf"},"id":"xPI4iKhpoULf","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"12b2d406","metadata":{"id":"12b2d406"},"outputs":[],"source":["# Read in encoding dataset\n","encoding_data = pd.read_csv(encoding_dataset_path, index_col = 0)"]},{"cell_type":"code","source":["#read in the Library of Novel Variant Sequences\n","data_pred = pd.read_csv(novel_library_path, index_col = 0)\n","\n","#check for any Duplicate Sequences\n","data_pred = data_pred.drop_duplicates(subset = data_pred.columns[2:-2],\n","                                      keep='first',\n","                                      inplace=False, ignore_index=False)\n","dropped = data_pred[data_pred.duplicated(subset = data_pred.columns[2:-2])]\n","\n","#tests\n","assert len(dropped) == 0"],"metadata":{"id":"62Y6Sgb65nQ5"},"id":"62Y6Sgb65nQ5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read in the encoding datasets:\n","top_encoding_data = pd.read_csv(top_encoding_dataset_path,index_col= 0)\n","top_encoding_data = top_encoding_data.sort_values(by = 'Test Set R Squared',\n","                                                          ascending = False)\n","names = [e[-10:] for e in top_encoding_data['Encoding Dataset'][0:5]]\n","\n","##tests\n","assert np.shape(names) == (5,)\n","assert top_encoding_data['Test Set R Squared'].iloc[0]>=top_encoding_data['Test Set R Squared'].iloc[1]"],"metadata":{"id":"--0M9OnB5qKg"},"id":"--0M9OnB5qKg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#initialize output dataframe\n","df_MPNR = pd.DataFrame()\n","save_path = parent_folder_path +'MPNR/'\n","\n","#Iterate through every encoding dataset + train model +\n","#record performance\n","for AA_property_dataset in tqdm(names,\n","                                desc = 'Property Datasets Encoded:'):\n","\n","    #format to match column names\n","    column_names_ref = 'AAindex: '+AA_property_dataset\n","\n","    # Make the train/test be on a copy to ensure there\n","    #is no data overwriting within loop\n","    x_train_copy = x_train.copy()\n","    x_test_copy = x_test.copy()\n","    x_pred_copy = data_pred.copy()\n","    x_full = encoded_df.copy()\n","\n","    #extract encoding data for specific iteration\n","    volume_dict = {'Amino Acid Code': encoding_data[encoding_data.columns[0]],\n","                   AA_property_dataset: encoding_data[column_names_ref]}\n","    volume_data = pd.DataFrame(volume_dict)\n","\n","\n","    #Some encoding datasets contain NaNs, I skip these\n","    #datasets since theyre incomplete\n","    #Next three lines check the encoding data for NaNs\n","    df = list(volume_data.iloc[:,1].values)\n","    T = np.isnan(df)\n","    TF = True in T\n","\n","    #If there is no NaN, perform model training\n","    if TF == False:\n","\n","        #initialize list to append to throughout training\n","        interlist = []\n","\n","        #Use volume_data as a codex to translate sequence data...\n","        # amino acids will translate to float type data\n","        col_title = volume_data.columns[1]\n","        for row, sample in enumerate(volume_data['Amino Acid Code']):\n","            amino = sample\n","            replacement_value = float(volume_data[col_title].iloc[row])\n","            x_train_copy = x_train_copy.replace(amino,replacement_value)\n","            x_test_copy = x_test_copy.replace(amino,replacement_value)\n","            x_pred_copy = x_pred_copy.replace(amino,replacement_value)\n","            x_full = x_full.replace(amino,replacement_value)\n","\n","        #Data Scaling\n","        scaler = RobustScaler()\n","        scaler.fit(x_full)\n","        x_train_copy = scaler.transform(x_train_copy)\n","        x_test_copy = scaler.transform(x_test_copy)\n","\n","        x_train_copy = pd.DataFrame(x_train_copy, columns = x_full.columns)\n","        x_test_copy = pd.DataFrame(x_test_copy, columns = x_full.columns)\n","\n","\n","        #apply SelectKBest class to extract best features\n","        bestfeatures = SelectKBest(score_func=mutual_info_regression, k='all')\n","        fit = bestfeatures.fit(x_train_copy,y_train)\n","        dfscores = pd.DataFrame(fit.scores_)\n","        dfcolumns = pd.DataFrame(x_train_copy.columns)\n","\n","        #concat two dataframes for better visualization\n","        featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","        featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n","\n","\n","        ##Hyper Parameter Tuning\n","        #Grid Search approach, I test every iteration to find the best\n","        # number of features\n","\n","        #Initialize the output lists to append to\n","        test_r2s = []\n","\n","        #For 25 possible best features\n","        for l in range(25):\n","\n","            if l > 0:\n","                cols = featureScores.nlargest(l,'Score')\n","\n","                #extract l features from X_train/X_test\n","                x_train_copy_ = x_train_copy[list(cols['Specs'].values)]\n","                x_test_copy_ = x_test_copy[list(cols['Specs'].values)]\n","\n","                #initialize model\n","                clf_RF = MLPRegressor(random_state = 42)\n","                #Fit the Train data\n","                clf_RF.fit(x_train_copy_, y_train)\n","                #Predict the Test set and generate metrics of fit\n","                y_RF = clf_RF.predict(x_test_copy_)\n","                test_r2s.append(sklearn.metrics.r2_score(y_test, y_RF))\n","\n","        #find which number of feature led to the\n","        #max R2, skip the zeroith index\n","        best_feats = test_r2s.index(max(test_r2s))\n","\n","\n","        #Extract the features that led to the best performance\n","        cols = featureScores.nlargest(best_feats+1,'Score')\n","        x_train_copy_ = x_train_copy[list(cols['Specs'].values)]\n","        x_test_copy_ = x_test_copy[list(cols['Specs'].values)]\n","        x_pred_copy_ = x_pred_copy[list(cols['Specs'].values)]\n","\n","        #initialize new model + fit data\n","        clf = MLPRegressor(random_state = 42)\n","        clf.fit(x_train_copy_, y_train)\n","\n","        #Create cross validation prediction\n","        y_pred = clf.predict(x_test_copy_)\n","\n","        #Save the overall R2 for the tuned model\n","        r2 = sklearn.metrics.r2_score(y_test, y_pred)\n","\n","        #append the data to a dataframe for export\n","        inter_df= pd.DataFrame({'Encoding Dataset': [AA_property_dataset[-11:]],\n","                                'Test Set R Squared' : [r2]})\n","\n","        df_MPNR = pd.concat([df_MPNR,inter_df],ignore_index = True)\n","\n","\n","        # Novel Library Predictions\n","        y_pred_new = clf.predict(x_pred_copy_)\n","        data_pred[dependent_variable +' Predicted'] = y_pred_new\n","        data_pred = data_pred.sort_values(by = dependent_variable +' Predicted',\n","                                          ascending = False)\n","        newmut = pd.DataFrame(data_pred)\n","\n","\n","        #Test Set Predictions\n","        test_set_df = pd.DataFrame()\n","        test_set_df['True'] = y_test\n","        test_set_df['Predicted'] = y_pred\n","\n","        #file saving\n","        newmut.to_csv(save_path + AA_property_dataset+'_novel_library_predictions.csv')\n","        test_set_df.to_csv(save_path + AA_property_dataset+'_test_set_predictions.csv')\n","\n","\n","        #FOR COLAB ONLY\n","        # save_path = '/content/drive/MyDrive/ml_paper_ipnys/MPNR_'\n","        # newmut.to_csv(save_path + AA_property_dataset+'_novel_library_predictions.csv')\n","        # test_set_df.to_csv(save_path + AA_property_dataset+'_test_set_predictions.csv')\n","\n","\n","assert len(df_MPNR) == 5\n","assert len(data_pred) == len(newmut)\n","assert len(test_set_df) == len(x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDDdUHc5osg2","outputId":"5d5e2030-9e57-45be-943d-e4a8139726ad","executionInfo":{"status":"ok","timestamp":1690068835528,"user_tz":420,"elapsed":76468,"user":{"displayName":"Sarah Wait","userId":"14055064724979742320"}}},"id":"GDDdUHc5osg2","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\rProperty Datasets Encoded::   0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","Property Datasets Encoded:: 100%|██████████| 5/5 [01:16<00:00, 15.26s/it]\n"]}]},{"cell_type":"code","execution_count":null,"id":"e4c42c7e","metadata":{"id":"e4c42c7e","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1690068835529,"user_tz":420,"elapsed":20,"user":{"displayName":"Sarah Wait","userId":"14055064724979742320"}},"outputId":"e08c91f1-151e-479f-9539-9206526c456f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Encoding Dataset  Test Set R Squared\n","2       ISOY800107            0.673465\n","0       BASU050103            0.668664\n","1       HUTJ700101            0.651879\n","3       GEIM800104            0.604670\n","4       ZIMJ680103            0.598853"],"text/html":["\n","\n","  <div id=\"df-aa8bcd4e-7a50-46f4-af69-456b6549628b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Encoding Dataset</th>\n","      <th>Test Set R Squared</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>ISOY800107</td>\n","      <td>0.673465</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>BASU050103</td>\n","      <td>0.668664</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>HUTJ700101</td>\n","      <td>0.651879</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GEIM800104</td>\n","      <td>0.604670</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ZIMJ680103</td>\n","      <td>0.598853</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa8bcd4e-7a50-46f4-af69-456b6549628b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-fc49b652-b94a-491e-b185-d1ddc41c9be4\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc49b652-b94a-491e-b185-d1ddc41c9be4')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-fc49b652-b94a-491e-b185-d1ddc41c9be4 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aa8bcd4e-7a50-46f4-af69-456b6549628b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aa8bcd4e-7a50-46f4-af69-456b6549628b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":15}],"source":["df_MPNR.sort_values(by='Test Set R Squared', ascending = False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}