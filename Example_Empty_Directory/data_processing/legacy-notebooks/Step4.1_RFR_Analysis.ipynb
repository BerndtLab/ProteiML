{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77ed7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running this shell will install/import necessary libraries to run the pipeline.\n",
    "\n",
    "\n",
    "# MAIN PACKAGES\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MODEL VALIDATION \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "#RFR SPECIFIC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def dataset_encoding(encoding_data, AA_property_dataset, x_train, x_test, x_data):\n",
    "    \n",
    "    \"\"\"takes in the name of the property, checks for NaNs, if no \n",
    "    Nans exist it encodes the x_train, x_test, and full x_data\n",
    "    outputs:\n",
    "        Boolean T/F for NaN existence,\n",
    "        property_encoding_data: dataframe with AA values and encoding information,\n",
    "        encoded_x_train: dataframe with encoded x_train data,\n",
    "        encoded_x_test: dataframe with encoded x_test data,\n",
    "        encoded_x_data: dataframe with encoded x_data\n",
    "        \"\"\"\n",
    "    AA_property_id = AA_property_dataset[-10:]\n",
    "\n",
    "    property_encoding_data = pd.DataFrame(\n",
    "        {'Amino Acid Code': encoding_data['Amino Acid Code'], \n",
    "         AA_property_id: encoding_data[AA_property_dataset]})\n",
    "    \n",
    "    #check to make sure that all amino acids have encoding information\n",
    "    T = np.isnan(list(property_encoding_data[AA_property_id]))\n",
    "    encoded_x_train = x_train.copy()\n",
    "    encoded_x_test = x_test.copy()\n",
    "    encoded_x_data = x_data.copy()\n",
    "\n",
    "    if True not in T:\n",
    "        #encoding_each_position\n",
    "        for row, sample in enumerate(property_encoding_data['Amino Acid Code']):\n",
    "            amino = sample\n",
    "            replacement_value = float(property_encoding_data[AA_property_id].iloc[row])\n",
    "            encoded_x_train = encoded_x_train.replace(amino,replacement_value)\n",
    "            encoded_x_test = encoded_x_test.replace(amino,replacement_value)\n",
    "            encoded_x_data = encoded_x_data.replace(amino,replacement_value)\n",
    "    return (True not in T), property_encoding_data, encoded_x_train, encoded_x_test, encoded_x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3939c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "variant_dataset_path = 'combined_dataset.csv' #@param {type:\"string\"}\n",
    "encoding_dataset_path = 'full_property_matrix.csv' #@param {type:\"string\"}\n",
    "novel_library_path = \n",
    "independent_variable_columns = [str(i) for i in np.arange(0,451)] #@param {type:\"list\"}\n",
    "dependent_variable_columns = '1 AP ∆F/F0' #@param {type:\"string\"}\n",
    "chosen_random_state = 42 #@param {type:\"raw\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe372eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test Split The Data\n",
    "#read in data and designate X/Y data\n",
    "data = pd.read_csv(variant_dataset_path,index_col = 0)\n",
    "encoding_data = pd.read_csv(encoding_dataset_path, index_col = 0)\n",
    "x_data = data[independent_variable_columns]\n",
    "y_data = data[dependent_variable_columns]\n",
    "\n",
    "\n",
    "#train and test splitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, \n",
    "                                                    y_data, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=chosen_random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa85a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property Datasets Encoded::  19%|█▊        | 105/566 [47:21<3:24:29, 26.62s/it]"
     ]
    }
   ],
   "source": [
    "#RFR\n",
    "RFR_output_df = pd.DataFrame()\n",
    "for AA_property_dataset in tqdm(encoding_data.columns[1:], desc = 'Property Datasets Encoded:'):\n",
    "\n",
    "  #dataset encoding, function defintion found in set-up cell\n",
    "    check, property_encoding_data, encoded_x_train, encoded_x_test, encoded_x_data = dataset_encoding(encoding_data, \n",
    "                                                                                                    AA_property_dataset, \n",
    "                                                                                                    x_train, x_test,\n",
    "                                                                                                    x_data)\n",
    "    #check for no NaNs in encoding dataset\n",
    "    if check == True:\n",
    "        model = RandomForestRegressor(random_state = 42)\n",
    "        model.fit(encoded_x_train,y_train)\n",
    "        feat_importances = pd.Series(model.feature_importances_, \n",
    "                                     index=encoded_x_train.columns)\n",
    "    \n",
    "        #initialize external saving location\n",
    "        n_est = []\n",
    "        test_r2s = []\n",
    "\n",
    "        #for features in range 21\n",
    "        for l in range(21): \n",
    "            if l > 0:\n",
    "                #isolate the l greatest feature importances in each encoded dataset\n",
    "                cols = list(feat_importances.nlargest(l).index)\n",
    "                x_train_copy_ = encoded_x_train[cols]\n",
    "                x_test_copy_ = encoded_x_test[cols]\n",
    "                \n",
    "                #intialize list of estimators to test\n",
    "                n_estimators = [10, 15, 20, 25, 30, 35, 40, \n",
    "                                45, 50, 55, 65, 75, 85, 100]\n",
    "                \n",
    "                #initialize external saving location\n",
    "                n_mse_list = []\n",
    "                n_r2_list = []\n",
    "                \n",
    "                #iterate through estimators to test estimators + feature...\n",
    "                #predictive capabilities\n",
    "                for estimators in n_estimators: \n",
    "                    clf_RF = RandomForestRegressor(n_estimators=estimators, \n",
    "                                                   random_state=42)\n",
    "                    clf_RF.fit(x_train_copy_, y_train)\n",
    "                    y_RF = clf_RF.predict(x_test_copy_)\n",
    "                    n_mse_list.append(mean_squared_error(y_test, y_RF))\n",
    "                    n_r2_list.append(sklearn.metrics.r2_score(y_test, y_RF))\n",
    "\n",
    "                best_est = n_estimators[n_mse_list.index(min(n_mse_list))]        \n",
    "                n_est.append(best_est)\n",
    "                test_r2s.append(np.mean(n_r2_list))\n",
    "\n",
    "        #determine best feature from hyperparameter tuning\n",
    "        best_feats = test_r2s.index(max(test_r2s))\n",
    "        est_best = n_est[best_feats]\n",
    "\n",
    "        #isolate important features in both train/test sets\n",
    "        cols = list(feat_importances.nlargest(best_feats).index)\n",
    "        encoded_x_train = encoded_x_train[cols]\n",
    "        encoded_x_test = encoded_x_test[cols]\n",
    "\n",
    "\n",
    "        #model initialization with best parameters\n",
    "        rfr = RandomForestRegressor(n_estimators = est_best, random_state = 42)\n",
    "\n",
    "        #fitting with important features data\n",
    "        rfr.fit(encoded_x_train, y_train)\n",
    "\n",
    "        #predictions on test and train sets\n",
    "        y_test_predicted = rfr.predict(encoded_x_test)\n",
    "        y_train_predicted = rfr.predict(encoded_x_train)\n",
    "\n",
    "        #output_metrics \n",
    "        r_squared = np.round(sklearn.metrics.r2_score(y_test, y_test_predicted),2)\n",
    "        r_squared_validation = np.round(sklearn.metrics.r2_score(y_train, y_train_predicted),2)\n",
    "        mse_ = np.round(mean_squared_error(y_test, y_test_predicted),2)\n",
    "\n",
    "        #saving to output matrix\n",
    "        iter_dict = {'Dataset Name': property_encoding_data.columns[1],\n",
    "                    'Test Set R Sqaured': r_squared,\n",
    "                    'Train Set R Squared': r_squared_validation,\n",
    "                    'MSE': mse_}\n",
    "        RFR_output_df = RFR_output_df.append(iter_dict, ignore_index = True)\n",
    "\n",
    "RFR_output_df =RFR_output_df.sort_values(by = 'Test Set R Sqaured', ascending = False)\n",
    "\n",
    "RFR_encoded_data_path = 'Random_Forest_Regressor_encoding_dataset_performance.csv'\n",
    "\n",
    "RFR_output_df.to_csv(RFR_encoded_data_path)\n",
    "\n",
    "print('File Saved to: ' + RFR_encoded_data_path)\n",
    "\n",
    "RFR_output_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a445a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
